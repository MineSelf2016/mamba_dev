{
    "architectures": [
      "MambaModel"
    ],
    "d_model": 512,
    "mamba_layer": 24,
    "torch_dtype": "float32",
    "transformers_version": "4.40.2",
    "vocab_size": 25426
}